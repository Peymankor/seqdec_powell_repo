{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter1: Modeling Sequential Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling Definition**: <br> Can be viewed as building a bridge from a messy, poorly defined real-world problem to something with the clarity and a computer can understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:47:24.797373Z",
     "start_time": "2020-12-18T09:47:24.795006Z"
    }
   },
   "source": [
    "## Five-Step Process for modeling Pocess:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: The narrative - English disccussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a first step that should give the modeler the big picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: The Mathematical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State Variable**: All information we need at time $t$  (or after $n$ iterations) from history to model the system from time $t$ (or $n$) onward. <br>\n",
    "**Decision variable**: How we are going to design or control our systems - Decisions wil be determined by *policies*, given what is in a state. <br>\n",
    "**Exogenous information**: The new information that arrives over time. <br>\n",
    "**The transition function**: equations that describe how the state variables evolve over time. In some cases, we do not even know the equations and had to depend on state variables.<br>\n",
    "**The Objective Function**: The performance matrics we use to evalute our performance, and provides basis for searching over *policies*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Uncertainity Model: \n",
    "This is how to model different type of uncertainty. beginning with identifying the different types of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Designing the Policies: \n",
    "*policies* are functions, so we have to search for the best function. We do this by defining, two core strategies , each divided into two major subclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluating Policies: \n",
    "Finding the *best policy* means evaluating policies to determine which is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Closer Look on five steps of Mathematical Modeling**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:58:48.472661Z",
     "start_time": "2020-12-18T09:58:48.469660Z"
    }
   },
   "source": [
    "The typycall approach the five elements of the model in step 2 as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Step 2a): **Identify the descions**: *design* decisions (begining of the process) from the *control* decision which are made over time.\n",
    "\n",
    "Step 2b): **Identify Metrics**: We typically want a single metrics (have an unambiguous way to compare solutions), but many problems have multiple metrics.\n",
    "\n",
    "step 2c): **Modeling Uncertainity**: initial belief and new information that arrives over time.\n",
    "\n",
    "step 2d): **The Transition Function:** we need to look the information in our state variable. for example, to model a price at time t+1, we might need the price at time $t+1$, we might need to know prices at time $t$, $t-1$ and $t-2$.\n",
    "\n",
    "step 2e): **Pulling together**: We need to write the objective functions (metrics) in term of state variables and decision from policy that dpends on the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Time Vs. Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:14:41.203515Z",
     "start_time": "2020-12-18T10:14:41.190920Z"
    }
   },
   "source": [
    "$x_{t}$:\n",
    "index variables such as our decision x by time t\n",
    "\n",
    "$x^{t}$: \n",
    "we assume we have one x that change with iterations, where $x^n$ is the value x  in the *nth* iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The mathematical Modeling Framework\n",
    "There are five basic elements to sequential descion problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State Variable:**\n",
    "\n",
    "The state $S_{t}$ of the system ate time t.\n",
    "There are **Three** of information in $S_{t}$:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The physical state: $R_{t}$:*<br>\n",
    "Is the state variable that is being controlled. $R_{t}$ maybe the scalar or vector, like amount of inventory at location i, $R_{ti}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Other information, $I_t$:*<br>\n",
    "which is any information that is known deterministically not included in $R_{t}$. The information state often evolves exogenously, but may be controlled or at least influenced by decsions. (e.g. selling a large number of shares may depress prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The belief State, $B_t$:* <br>\n",
    "contains information about a probability distribution describing one or more unknown parameters. Thus, $B_{t}$ could capture the mean or variance of normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:39:40.188563Z",
     "start_time": "2020-12-18T12:39:40.181262Z"
    }
   },
   "source": [
    "**Imprtant**: The $S_{t}$ is sometimes referred to as the *pre-decision state* because it is the state just before we make a decsions.\n",
    "\n",
    "**$S_{t}^{x}$** : Is the state *immediately after we make* a decision , but before any new information has arrived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:43:46.792122Z",
     "start_time": "2020-12-18T12:43:46.787506Z"
    }
   },
   "source": [
    "**Example**:\n",
    "In a basic inventory problem where \n",
    "$R_{t+1} = max ({0, R_{t} + x_{t}-D_{t+1}})$\n",
    "\n",
    "The post decsion would be (the state after we have implemented decsion , but before any new information):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:47:43.432573Z",
     "start_time": "2020-12-18T12:47:43.427655Z"
    }
   },
   "source": [
    "$S_{t}^{x}= R_{t}^{x}=R_{t} + x_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Variable**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decisions are typically represented as $a_{t}$ for discrete actions, $u_{t}$ for continous  (vector-valuaed) controls, and $x_{t}$ for general continous or discerete vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note to understand Decision and Policy**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that decision are made with *policy*, which we might denote:\n",
    "<br>\n",
    "$X^{\\pi}(S_{t})$, $A_{\\pi}(S_{t})$, $U_{\\pi}(S_{t})$\n",
    "<br>\n",
    "We assume that decision $x_{t}=X^{\\pi}(S_t)$ is feasible at time t.\n",
    "We let \"$\\pi$\" carry the information about the type of function, for example a linear model with specific explanatory variables, or a particular non linear model) and *any* tunable parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exogenous information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let $W_t$ be any new information that first becomes known at time $t$ (that is, between $t-1$ and $t$).."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: When modeling specific variables, we use \"hats\" to indicate exogenous information. Thus $\\hat{D}$ could be the demand that arises between $t-1$ and $t$, or we could let $\\hat{p_{t}}$ be the change in the price between $t-1$ and $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let $\\omega$ represent a sample path $W_1$,..., $W_{T}$, where $\\omega$ belongs to $\\Omega$ creates a set of discerete samples that we might represent using ($\\omega_{1}$, $\\omega_{2}$,..., $\\omega_{N}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T13:18:08.365511Z",
     "start_time": "2020-12-18T13:18:08.361987Z"
    }
   },
   "source": [
    "$$S_{t+1} = S^{M}(S_{t}, x_{t}, W_{t+1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S^M(.)$ is also knwon by names such as system model, plant model, plant equation, state equation and transfer learning.\n",
    "<br>\n",
    "**Classic** form of transition function which gives the equation from pre decision state $S_t$ to pre decision state $S_{t+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In another word, we can break down equations into two steps: pre descion plus decsion reaches to post decsions $S_{t}^x$, and then post decision to $S_{t}^{x}$ to the next pre decision $S_{t+1}$. \n",
    "* The transition function may be known set of equations ....\n",
    "* When the equations are unknown the problem is often described as the **model free** or **data-driven**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:06:05.746709Z",
     "start_time": "2020-12-21T09:06:05.743898Z"
    }
   },
   "source": [
    "Given a policy $X^{\\pi}(S_t)$ , an exogenous process $W_t$ and a transition function, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:06:57.375725Z",
     "start_time": "2020-12-21T09:06:57.367873Z"
    }
   },
   "source": [
    "**Important Sequence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:07:57.288618Z",
     "start_time": "2020-12-21T09:07:57.284160Z"
    }
   },
   "source": [
    "$$(S_0, x_0,S_0^{x}, W_1, S_1, x_1, S_{1}^x, W_2,..., x_{T-1},S_{T-1}^x, W_{T}, S_{T})$$\n",
    "<br>\n",
    "The default is we use iteration n where there is some other proces such as running experienmnt ... if we use n, then we will write states, decsions and information as $S^n$, $x^n$ and $W^{n+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:15:06.999068Z",
     "start_time": "2020-12-21T09:15:06.994548Z"
    }
   },
   "source": [
    "Two classes of the **Objective Function**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type 1: Final Reward*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T10:15:20.824988Z",
     "start_time": "2020-12-21T10:15:20.821208Z"
    }
   },
   "source": [
    "Here we wish to find a design x to maximize $E_W F(x, W)$ - We are going to focus on adaptive algorithm , or policies , that will produce a solution $x^{x,N}$.\n",
    "<br>\n",
    "We can then write our final (or terminal) reward objective function as:\n",
    "<br>\n",
    "<br>\n",
    "$$max E [F(x, W)|S_0]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the transition function is:\n",
    "<br>\n",
    "$$ S^{n+1} = S^M(S^n, X^{\\pi}(S^n), W^{n+1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type 2: Cumulative Reward*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that we are maximizing contributions (or some utility) which we write as $C(S_t, x_t)$ to express its possible dependence on the state $S_t$.\n",
    "<br>\n",
    "which might contain a price or othe rparameters that vary dramatically over time and action $x_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T12:03:37.127692Z",
     "start_time": "2020-12-21T12:03:37.117370Z"
    }
   },
   "source": [
    "$$\n",
    " \\max_{\\pi} \\quad \\mathbb{E} \\Big\\{ {\\sum_{t=0}^{T}C_t(S_t, X_t^{\\pi}(S_t),W_{t+1}|S_0}\\Big\\} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    " S_{t+1} = S^M(S_t, X_t^{\\pi}(S_t), W_{t+1}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "Using this notation, we note that *any* sequential decision problem can be modeled as a sequence of (pre-decsion) states, decisions, post-decision states, exogenous information, back to (pre-decision) states. we can write this as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(S_0, x_0, S_0^{x}, W_1, S_1, x_1, S_1^{x}, W_2,...)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Throughout the excersices in the chapters as follows, we will always be trying to find a good policy, which might be the best in a class, or sometimes the best over all (the true optimal policy)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('miniconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitminiconda3virtualenve74fedcb21d34eb1870d0e92f04bd4f6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
