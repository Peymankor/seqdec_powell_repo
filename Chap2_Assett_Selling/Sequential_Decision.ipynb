{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Sequential Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:47:24.797373Z",
     "start_time": "2020-12-18T09:47:24.795006Z"
    }
   },
   "source": [
    "## The Modeling Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: The narrative - English disccussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : The mathematical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State Variable:\n",
    "#### Decision variable: How we are going to design or control our systems\n",
    "#### Exogenous information: The new information that arrives over time\n",
    "#### The transition function: equations that describe how the state variables evolve over time\n",
    "#### The Objective Function: The performance matrics we use to evalute our performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Uncertainity Model: how to model different type of uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Designing the Policies : two core strategies , each divided into two major subclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluating Policies: Finding the best policy means evaluating policies to determine which is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:58:48.472661Z",
     "start_time": "2020-12-18T09:58:48.469660Z"
    }
   },
   "source": [
    "The typycall approach the five elements of the model in step 2 as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Step 2a): Identify the descions: design decsions (begining of the process) from the contro, decsion which are made over time\n",
    "\n",
    "Step 2b): Identify Metrics: We typically want a single metrics, but many problems have multiple metrics\n",
    "\n",
    "step 2c): Modeling Uncertainity: initial belief and new information that arrives over time.\n",
    "\n",
    "step 2d): The transition function: we need to look the information in our state variable. for example, to model a price at time t+1, we might need the price at time t, t-1, t-2\n",
    "\n",
    "step 2e): We need to write the objective functions (metrics) in term of state variables and decision from policy that dpends on the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Time Vs. Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:14:41.203515Z",
     "start_time": "2020-12-18T10:14:41.190920Z"
    }
   },
   "source": [
    "$x_{t}$:\n",
    "index variables such as our decision x by time t\n",
    "\n",
    "$x^{t}$: \n",
    "we assume we have one x that change with iterations, where $x^n$ is the value x  in the *nth* iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The mathematical Modeling Framework\n",
    "There are five basic elements to sequential descion problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Variable:\n",
    "\n",
    "The state $S_{t}$ of the system ate time t. Teh three types of information in $S_{t}$:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The physical state: $R_{t}$:\n",
    "Is the state variable that is being controlle. $R_{t}$ maybe the scalar or vector, like amount of inventory at location i, $R_{ti}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other information, $I_t$:\n",
    "which is any information that is known deterministically not included in $R_{t}$. The information state often evolves exogenously, but may be controlled or at least influenced by decsions. (e.g. selling a large number of shares may depress prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The belief State, $B_t$: \n",
    "contains information about a probability distribution describing one or more unknown parameters. Thus, $B_{t}$ could capture the mean or variance of normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:39:40.188563Z",
     "start_time": "2020-12-18T12:39:40.181262Z"
    }
   },
   "source": [
    "**Imprtant**: The $S_{t}$ is sometimes referred to as the *pre-decision state* because it is the state just before we make a decsions.\n",
    "\n",
    "**$S_{t}^{x}$** : Is the state *immediately after we make* a decision , but before any new information has arrived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:43:46.792122Z",
     "start_time": "2020-12-18T12:43:46.787506Z"
    }
   },
   "source": [
    "**Example**:\n",
    "In a basic inventory problem where \n",
    "$R_{t+1} = max ({0, R_{t} + x_{t}-D_{t+1}})$\n",
    "\n",
    "The post decsion would be (the state after we have implemented decsion , but before any new information):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T12:47:43.432573Z",
     "start_time": "2020-12-18T12:47:43.427655Z"
    }
   },
   "source": [
    "$S_{t}^{x}= R_{t}^{x}=R_{t} + x_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decisions are typically represented as $a_{t}$ for discrete actions, $u_{t}$ for continous  (vector-valuaed) controls, and $x_{t}$ for general continous or discerete vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that decision are made with policy, which we might denote:\n",
    "<br>\n",
    "$X^{\\pi}(S_{t})$, $A_{\\pi}(S_{t})$, $U_{\\pi}(S_{t})$\n",
    "<br>\n",
    "We assume that decision $x_{t}=X^{\\pi}(S_t)$ is feasible at time t.\n",
    "We let \"$\\pi$\" carry the information about the type of function, for example a linear model with specific explanatory variables, or a particular non linear model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exogenous information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let $W_t$ be any new information that first becomes known at time $t$ (that is, between $t-1$ and $t$).."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: When modeling specific variables, we use \"hats\" to indicate exogenous information. Thus $\\hat{D}$ could be the demand that arises between $t-1$ and $t$, or we could let $\\hat{p_{t}}$ be the change in the price between $t-1$ and $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let $\\omega$ represent a sample path $W_1$,..., $W_{T}$, where $\\omega$ belongs to $\\Omega$ creates a set of discerete samples that we might represent using ($\\omega_{1}$, $\\omega_{2}$,..., $\\omega_{N}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T13:18:08.365511Z",
     "start_time": "2020-12-18T13:18:08.361987Z"
    }
   },
   "source": [
    "$S_{t+1} = S^{M}(S_{t}, x_{t}, W_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S^M(.)$ is also knwon by names such as system model, plant model, plant equation, state equation and transfer learning.\n",
    "<br>\n",
    "**Classic** form of transition function which gives the equation from pre decision state $S_t$ to pre decision state $S_{t+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In another word, we can break down equations into two steps: pre descion plus decsion reaches to post decsions $S_{t}^x$, and then post decision to $S_{t}^{x}$ to the next pre decision $S_{t+1}$. \n",
    "* The transition function may be known set of equations ....\n",
    "* When the equations are unknown the problem is often described as the **model free** or **data-driven**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:06:05.746709Z",
     "start_time": "2020-12-21T09:06:05.743898Z"
    }
   },
   "source": [
    "Given a policy $X^{\\pi}(S_t)$ , an exogenous process $W_t$ and a transition function, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:06:57.375725Z",
     "start_time": "2020-12-21T09:06:57.367873Z"
    }
   },
   "source": [
    "**Important Sequence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:07:57.288618Z",
     "start_time": "2020-12-21T09:07:57.284160Z"
    }
   },
   "source": [
    "($S_0, x_0,S_0^{x}, W_1, S_1, x_1, S_{1}^x, W_2,..., x_{T-1},S_{T-1}^x, W_{T}, S_{T}$)\n",
    "<br>\n",
    "The default is we use iteration n where there is some other proces such as running experienmnt ... if we use n, then we will write states, decsions and information as $S^n$, $x^n$ and $W^{n+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T09:15:06.999068Z",
     "start_time": "2020-12-21T09:15:06.994548Z"
    }
   },
   "source": [
    "Two classes of the **Objective Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T10:15:20.824988Z",
     "start_time": "2020-12-21T10:15:20.821208Z"
    }
   },
   "source": [
    "Here we wish to find a design x to maximize $E_W F(x, W)$ - We are going to focus on adaptive algorithm , or policies , that will produce a solution $x^{x,N}$.\n",
    "<br>\n",
    "We can then write our final (or terminal) reward objective function as:\n",
    "<br>\n",
    "<br>\n",
    "$max E [F(x, W)|S_0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the transition function is:\n",
    "<br>\n",
    "$S^{n+1} = S^M(S^n, X^{\\pi}(S^n), W^{n+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that we are maximizing contributions (or some utility) which we write as $C(S_t, x_t)$ to express its possible dependence on the state $S_t$.\n",
    "<br>\n",
    "which might contain a price or othe rparameters that vary dramatically over time and action $x_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T12:03:37.127692Z",
     "start_time": "2020-12-21T12:03:37.117370Z"
    }
   },
   "source": [
    "$$\n",
    "\\begin{equation*}\n",
    "\\Large max \\quad \\mathbb{E} \\Big\\{ {\\sum_{t=0}^{T}C_t(S_t, X_t^{\\pi}(S_t),W_{t+1}|S_0}\\Big\\}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation*}\n",
    "\\Large S_{t+1} = S^M(S_t, X_t^{\\pi}(S_t), W_{t+1}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "Using this notation, we note that *any* sequential decision problem can be modeled as a sequence of (pre-decsion) states, decisions, post-decision states, exogenous information, back to (pre-decision) states. we can write this as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\Large (S_0, x_0, S_0^{x}, W_1, S_1, x_1, S_1^{x}, W_2,...)\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Throughout the excersices in the chapters as follows, we will always be trying to find a good policy, which might be the best in a class, or sometimes the best over all (the tru optimal policy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Asset Selling Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to sell an asset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T12:33:31.902426Z",
     "start_time": "2020-12-21T12:33:31.899054Z"
    }
   },
   "source": [
    "* State Variable: $S_t$ that captures all the information we need ...($R_t$, $I_t$, $B_t$)\n",
    "* Decsion Variable : $x_t$ where $x_0$ is the design decision, while $x_t$ for t>0 represents control varilables.\n",
    "* Exogenous information\n",
    "* Transition fucntion\n",
    "* Objective Function: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are holding a block of shares of stock, looking for oppurtunity to sell.If we sell at time t, we receive a price that varies according to some random process over time. Once we sell the stock, the process stops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two state variable:\n",
    "* The **Physical State** which says whether or not we are still holding the assest\n",
    "* The **Information State** the price of stock "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The physical State:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "  R_t=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if we are holding the stock at time t}\\  \\\\\n",
    "    0, & \\text{if we are not longer holding the stock at time t}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} \n",
    "$$\n",
    "\n",
    "If we sell the stock, we receive the price per share $p_t$. This means our state variable is:\n",
    "$$\n",
    "S_t=(R_t, p_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T13:41:09.474173Z",
     "start_time": "2020-12-21T13:41:09.467788Z"
    }
   },
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "  x_t=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if we sell the stock at time t}\\  \\\\\n",
    "    0, & \\text{if we do not sell the stock at time t}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} \n",
    "$$\n",
    "we only can sell stock if we hold it,\n",
    "$$\n",
    "x_t < R_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy\n",
    "\n",
    "What is the policy?\n",
    "\n",
    "$$\n",
    "X^{\\pi}(S_t)\n",
    "$$\n",
    "\n",
    "Example policy is we might be to sell if the price drops the below some limit point, thus we could write:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  X^{sell-low}(S_t|\\theta^{low})=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if}\\ p_t<\\theta^{low}  \\ \\text{and}\\ R_t=1  \\\\\n",
    "    1, & \\text{if}\\ t= T\\ \\text{and} \\ R_t = 1 \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exogenous Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only random process in our basic model is the change in price. Alternatively, naturally we simply write $W_t$ be the new price, in which we would write:\n",
    "\n",
    "$$\n",
    "W_{t+1} = (p_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the equation that describe how the states evolves. The transition equation is:\n",
    "\n",
    "$$\n",
    "R_{t+1} = R_{t} - x_{t}\n",
    "$$\n",
    "\n",
    "How the price evolves over time. \n",
    "\n",
    "$$p_{t+1} = p_t  + \\hat{p}_{t+1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "S_{t+1} = S^M(S_t, X^{\\pi}(S_t), W_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "The performance metric is how much we earn from selling our stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:16:26.040468Z",
     "start_time": "2020-12-21T14:16:26.037354Z"
    }
   },
   "source": [
    "$$\n",
    "C(S_t,x_t) = p_tx_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can formulate the optimizatio problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:19:50.538018Z",
     "start_time": "2020-12-21T14:19:50.528895Z"
    }
   },
   "source": [
    "$$\n",
    "max \\ \\sum_{t=0}^{T-1} p_tx_t \\\\\n",
    "x_0,x_1,...,x_{T-1}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('miniconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitminiconda3virtualenve74fedcb21d34eb1870d0e92f04bd4f6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
